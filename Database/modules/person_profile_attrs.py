# modules/person_profile_attrs.py
# -*- coding: utf-8 -*-
"""
äººç‰©æ•°æ®å±æ€§å±¥å†ï¼ˆæ¨¡å—åŒ–ï¼‰
- æš´éœ² run(st) ä¾›ä¸»å…¥å£è°ƒç”¨ã€‚
- ä¼˜å…ˆå¤ç”¨ä¸»å…¥å£è®¾ç½®çš„å…¨å±€æ•°æ®æºï¼šst.session_state['kd_data_path'] â†’ è‡ªåŠ¨åŠ è½½ Graph å¹¶ä½¿ç”¨ï¼›
  è‹¥æœªè®¾ç½®ï¼Œåˆ™å›è½åˆ°æœ¬æ¨¡å—ä¾§æ çš„â€œæ‰‹åŠ¨åŠ è½½â€ã€‚
- å¸ƒå±€ï¼šä¸»å†…å®¹ 8 / æº¯æº 4ï¼›é¡¶éƒ¨æœç´¢æ  8 / 4ï¼›å‡å°å·¦å³ç•™ç™½ã€‚
- æº¯æºï¼šPropAssertion.about â†’ TextProvenanceï¼ˆç¹ç®€ä½“è”åŠ¨é«˜äº®ï¼‰ã€‚
"""

import unicodedata
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set, Union

import streamlit as st
from rdflib import Graph, URIRef, RDF, Literal
from rdflib.namespace import RDFS, SKOS, FOAF

# ====== å¸¸é‡ ======
NS = "http://mingkg.org/ontology/imperial_exam.owl#"
ABOUT        = NS + "about"          # PropAssertion -> owl:Thing
DERIVED_FROM = NS + "derivedFrom"    # PropAssertion -> TextProvenance

PA_PROP   = NS + "prop"
PA_VAL    = NS + "value"
PA_VALN   = NS + "value_norm"
TP_CONF   = NS + "record_confidence"
TP_SRC    = NS + "Text_source"
TP_BODY   = NS + "Text_body"

# Person æ•°æ®å±æ€§å€™é€‰ï¼ˆæœ¬åœ°åï¼›æŒ‰ä½ çš„æœ¬ä½“ï¼‰
PERSON_DP_LOCAL = [
    "å§“å", "å­—", "å­¦æœ¯ä¸“é•¿", "å­¦ç±", "å®¶åº­æ’è¡Œ", "æˆ·ç±åœ°", "æˆ·ç±ç±»å‹", "ç”Ÿå¹´",
    str(RDFS.label).rsplit("/",1)[-1],  # rdfs_labelï¼ˆå®¹é”™ï¼‰
]

# å…è®¸æº¯æºçš„å±æ€§ï¼ˆç™½åå•ï¼‰
ALLOWED_FOR_PROV = set(PERSON_DP_LOCAL) | {"å§“å", "å­—", "å­¦æœ¯ä¸“é•¿", "å­¦ç±", "å®¶åº­æ’è¡Œ", "æˆ·ç±åœ°", "æˆ·ç±ç±»å‹", "ç”Ÿå¹´"}

# ====== æ ·å¼ï¼ˆæ”¾è¿™é‡Œä»¥ä¾¿ run å†…æ³¨å…¥ä¸€æ¬¡ï¼Œä¸è°ƒç”¨ set_page_configï¼‰ ======
CSS = """
<style>
.block-container {
  max-width: 96vw;
  padding-left: 8px;
  padding-right: 8px;
}
.hint { color:#94a3b8; font-size:12px; }
.small { color:#64748b; font-size:12px; }
.card { border:1px solid #ececec; border-radius:12px; padding:12px 14px; margin:10px 0; background:#fff; box-shadow:0 1px 3px rgba(0,0,0,.04); }
.grid6 { display:grid; grid-template-columns: repeat(3, minmax(0, 1fr)); grid-gap:8px; margin-top:8px; }
.chip { width:100%; border:1px solid #c7d2fe; background:#eef2ff; color:#1e293b; border-radius:999px; padding:8px 10px; font-size:13px; text-align:center; cursor:pointer;}
.chip:hover { background:#e0e7ff;}
.mark { background: #fde68a; padding: 0 3px; border-radius: 4px; }
.badge {display:inline-block; padding:2px 8px; border-radius:999px; font-size:12px; background:#eef2ff; color:#0f172a; margin-left:8px; border:1px solid #e2e8f0;}
</style>
"""

# ====== å·¥å…·å‡½æ•°ï¼ˆçº¯å‡½æ•°ï¼‰ ======
_ZW = {u"\u200b", u"\u200c", u"\u200d", u"\ufeff"}

def norm(s: str) -> str:
    if s is None: return ""
    s = unicodedata.normalize("NFKC", s)
    s = "".join(ch for ch in s if (not ch.isspace()) and (ch not in _ZW))
    return s

def localname_str(u: Union[URIRef, str]) -> str:
    s = str(u)
    for sep in ("#", "/", ":"):
        if sep in s:
            s = s.rsplit(sep, 1)[-1]
    return s

@st.cache_data(show_spinner=False)
def load_graph_any(path: str) -> Graph:
    p = Path(path)
    data = p.read_bytes()
    g = Graph()
    # å®¹é”™ï¼šä¼˜å…ˆ ntï¼›å¤±è´¥é€€å› turtleï¼›å†é€€å› rdflib è‡ªåŠ¨åˆ¤å®š
    try:
        g.parse(data=data, format="nt")
    except Exception:
        try:
            g = Graph(); g.parse(data=data, format="turtle")
        except Exception:
            g = Graph(); g.parse(data=data)
    return g

def find_instances(g: Graph, class_local: str) -> List[URIRef]:
    out = []
    for s, t in g.subject_objects(RDF.type):
        if isinstance(s, URIRef) and localname_str(t) == class_local:
            out.append(s)
    return out

def get_literals_map(g: Graph, node: URIRef) -> Dict[str, List[str]]:
    res: Dict[str, List[str]] = {}
    for p, o in g.predicate_objects(node):
        if isinstance(o, Literal):
            k = localname_str(p)
            res.setdefault(k, []).append(str(o).strip())
    return res

def get_first_display(props: Dict[str, List[str]], keys_local: List[str]) -> str:
    for k in keys_local:
        lk = localname_str(k)
        if lk in props and props[lk]:
            return props[lk][0]
    # å…œåº•ï¼šä»»æ„éç©ºæ–‡å­—å±æ€§
    for vs in props.values():
        for v in vs:
            if v.strip():
                return v
    return ""

# â€”â€” æº¯æºï¼ˆç¹ç®€ä½“è”åŠ¨ï¼‰ â€”â€” #
TS_MAP = {
    "è˜‡":"è‹","åŠ‰":"åˆ˜","å¼µ":"å¼ ","è¶™":"èµµ","éŒ¢":"é’±","å­«":"å­™","åœ‹":"å›½","æœƒ":"ä¼š","è©¦":"è¯•","é„‰":"ä¹¡",
    "é€²":"è¿›","èˆ‰":"ä¸¾","éš":"é˜¶","ç´š":"çº§","æ­·":"å†","é„­":"éƒ‘","é»ƒ":"é»„","è¬":"ä¸‡","é™³":"é™ˆ","æ¥Š":"æ¨",
    "é¦¬":"é©¬","è¨±":"è®¸","é„§":"é‚“","å³":"å´","è‘‰":"å¶","ç¾…":"ç½—","é½Š":"é½","ç¥¿":"ç¦„","ç¥¯":"ç¥¯","ç¦":"ç¥¯"
}
def t2s(s: str) -> str: return "".join(TS_MAP.get(ch, ch) for ch in s)
def s2t(s: str):
    inv = getattr(s2t, "_inv", None)
    if inv is None:
        inv = {v:k for k,v in TS_MAP.items()}
        s2t._inv = inv
    return "".join(inv.get(ch, ch) for ch in s)

def fuzzy_contains_name(text: str, names: List[str]) -> bool:
    if not text or not names: return False
    t_raw = norm(text); t_s = t2s(t_raw); t_t = s2t(t_raw)
    for name in names:
        n_raw = norm(name); n_s = t2s(n_raw); n_t = s2t(n_raw)
        if (n_raw and n_raw in t_raw) or (n_s and n_s in t_s) or (n_t and n_t in t_t):
            return True
    return False

def objects_literals(g: Graph, s: URIRef, prop_uri: str) -> List[Literal]:
    return [o for o in g.objects(s, URIRef(prop_uri)) if isinstance(o, Literal)]

def txt_list(g: Graph, s: URIRef, prop_uri: str) -> List[str]:
    vals, seen = [], set()
    for lit in objects_literals(g, s, URIRef(prop_uri)):
        v = str(lit).strip()
        if v and v not in seen:
            seen.add(v); vals.append(v)
    return vals

def prop_assertions_about(g: Graph, node: URIRef) -> List[URIRef]:
    return [pa for pa in g.subjects(URIRef(ABOUT), node)]

def pa_core_tuple(g: Graph, pa: URIRef) -> Tuple[str, str]:
    prop = next(iter(txt_list(g, pa, PA_PROP)), "")
    valn = next(iter(txt_list(g, pa, PA_VALN)), "")
    if valn:
        return prop, valn
    val = next(iter(txt_list(g, pa, PA_VAL)), "")
    return prop, val

def pa_to_provenances(g: Graph, pa: URIRef) -> List[URIRef]:
    return [tp for tp in g.objects(pa, URIRef(DERIVED_FROM)) if isinstance(tp, URIRef)]

def highlight_value(text: str, value: str) -> str:
    if not text or not value: return text
    t = text
    cands = list(dict.fromkeys([value, t2s(value), s2t(value)]))
    for v in cands:
        vv = v.strip()
        if vv:
            t = t.replace(vv, f"<span class='mark'>{vv}</span>")
    return t

def person_aliases(g: Graph, p: URIRef) -> List[str]:
    props = get_literals_map(g, p)
    candidates = ["å§“å", "name", "label", "rdfs_label", "æ ‡é¢˜", "title",
                  str(FOAF.name), str(RDFS.label), str(SKOS.prefLabel)]
    vals = []
    for k in candidates:
        lk = localname_str(k)
        vals.extend(props.get(lk, []))
    out, seen = [], set()
    for v in vals:
        v = (v or "").strip()
        if v and v not in seen:
            seen.add(v); out.append(v)
    return out

def provenance_groups_for(node: URIRef, g: Graph, person_alias: List[str], allowed_props: Set[str]) -> List[Dict]:
    groups: Dict[Tuple[str,str], Dict] = {}
    def _n(s): return norm(s or "")
    for pa in prop_assertions_about(g, node):
        prop, val = pa_core_tuple(g, pa)
        if not prop or not val:
            continue
        prop_local = localname_str(prop)
        if prop_local not in allowed_props and prop not in allowed_props:
            continue
        for tp in pa_to_provenances(g, pa):
            srcs  = txt_list(g, tp, TP_SRC)
            confs = txt_list(g, tp, TP_CONF)
            bodys = txt_list(g, tp, TP_BODY)
            src  = srcs[0] if srcs else ""
            body = bodys[0] if bodys else ""
            if not body:
                continue
            if not fuzzy_contains_name(body, person_alias):
                continue
            key = (_n(src), _n(body))
            G = groups.setdefault(key, {"src": src or "ï¼ˆæœªçŸ¥ä¹¦ç›®ï¼‰", "body": body, "conf": "", "items": set()})
            if confs:
                try:
                    cur = float(G["conf"]) if G["conf"] else -1e9
                    valf = float(confs[0])
                    if valf > cur:
                        G["conf"] = confs[0]
                except Exception:
                    pass
            G["items"].add((prop_local if prop_local else str(prop), val))
    ordered = sorted(groups.values(), key=lambda d: (0 if d["src"] else 1, d["src"], d["body"]))
    return ordered

# ====== æ–°å¢ï¼šä¸å…¥å£å¯¹æ¥çš„å…¨å±€åŠ è½½å™¨ï¼ˆæ–¹æ¡ˆ Aï¼‰ ======
def _ensure_graph_from_global() -> Tuple[Optional[Graph], bool]:
    """
    è‹¥å…¥å£å·²è®¾ç½® kd_data_pathï¼Œåˆ™è‡ªåŠ¨åŠ è½½ Graph å¹¶å†™å…¥ï¼š
      - st.session_state['graph']
      - st.session_state['loaded_file']
    è¿”å› (Graph or None, æ˜¯å¦æœ¬æ¬¡é‡æ–°åŠ è½½)
    """
    kd_path = (st.session_state.get("kd_data_path") or "").strip()
    if not kd_path:
        return None, False
    cur_loaded = st.session_state.get("loaded_file", "")
    g = st.session_state.get("graph")
    if g is not None and cur_loaded == kd_path:
        return g, False
    try:
        g = load_graph_any(kd_path)
        st.session_state["graph"] = g
        st.session_state["loaded_file"] = kd_path
        return g, True
    except Exception as e:
        st.error(f"å…¨å±€æ•°æ®æºåŠ è½½å¤±è´¥ï¼š{e}")
        return None, False

# ====== é¡µé¢å­é€»è¾‘ï¼ˆåªåœ¨ run å†…è°ƒç”¨ï¼‰ ======
def _search_persons(g: Graph, query: str) -> List[Tuple[str, str, str]]:
    persons = find_instances(g, "Person")
    qn = norm(query.strip())
    hits = []
    for p in persons:
        props = get_literals_map(g, p)
        names = []
        for k in ["å§“å", str(FOAF.name), str(RDFS.label), str(SKOS.prefLabel), "æ ‡é¢˜", "title", "label", "rdfs_label"]:
            lk = localname_str(k)
            names.extend(props.get(lk, []))
        names = [n for n in names if n.strip()]
        if not names:
            continue
        reason = ""
        for v in names:
            if qn and norm(v) == qn:
                reason = f"[ç­‰å€¼å‘½ä¸­] {v}"; break
        if not reason:
            for v in names:
                if qn and qn in norm(v):
                    reason = f"[åŒ…å«å‘½ä¸­] {v}"; break
        if reason:
            hits.append((str(p), names[0], reason))
    hits.sort(key=lambda t: (t[1]))
    return hits[:50]

def _render_person_block(g: Graph, person_iri: str):
    person = URIRef(person_iri)
    props = get_literals_map(g, person)
    display_name = get_first_display(props, ["å§“å", str(FOAF.name), str(RDFS.label), str(SKOS.prefLabel)]) or localname_str(person)
    st.markdown(f"### {display_name}  <span class='hint'>{person_iri}</span>", unsafe_allow_html=True)

    # ç»„è£…å±•ç¤ºé”®å€¼ï¼ˆåªå–ç™½åå•ï¼‰
    kvs: List[Tuple[str, str]] = []
    for key in PERSON_DP_LOCAL:
        lk = localname_str(key)
        vals = props.get(lk, [])
        for v in vals:
            v = v.strip()
            if v:
                kvs.append((lk, v))

    if not kvs:
        st.info("ï¼ˆè¯¥äººç‰©æš‚æ— å¯å±•ç¤ºçš„æ•°æ®å±æ€§ï¼‰")
        return

    # æ¸²æŸ“ Chipï¼ˆç‚¹å‡»å…¥æº¯æºï¼‰
    st.markdown("<div class='card'><div class='small'>æ•°æ®å±æ€§</div>", unsafe_allow_html=True)
    st.markdown("<div class='grid6'>", unsafe_allow_html=True)
    aliases = person_aliases(g, person)

    def _set_prov(node_iri: str, prop_name: str, prop_value: str, aliases: List[str]):
        st.session_state["__pp_attrs_prov__"] = (node_iri, prop_name, prop_value, aliases)

    for i, (k, v) in enumerate(kvs):
        key_btn = f"pp_attrs_chip_{hash((person_iri, k, v))}_{i}"
        st.button(f"{k}ï¼š{v}", key=key_btn, on_click=_set_prov,
                  args=(person_iri, k, v, aliases), use_container_width=True)
    st.markdown("</div></div>", unsafe_allow_html=True)

# ====== å¯¹å¤–å…¥å£ ======
def run(st):
    """ä¸»å…¥å£ï¼šç”± app.py è°ƒç”¨ person_profile_attrs.run(st)"""
    # ä»…åœ¨æœ¬æ¨¡å—é¡µé¢æ¸²æŸ“æ—¶æ³¨å…¥ CSSï¼ˆä¸é‡å¤ set_page_configï¼‰
    st.markdown(CSS, unsafe_allow_html=True)

    # ä¼˜å…ˆå¤ç”¨ä¸»å…¥å£çš„å…¨å±€æ•°æ®æºï¼ˆkd_data_pathï¼‰
    g, reloaded = _ensure_graph_from_global()

    # ä¾§æ ï¼šä»…å½“å…¨å±€æœªè®¾ç½® kd_data_path æ—¶ï¼Œæ‰æ˜¾ç¤ºæœ¬æ¨¡å—çš„æ‰‹åŠ¨åŠ è½½ UI
    if g is None:
        with st.sidebar:
            st.header("ğŸ“ æ•°æ®")
            data_file = st.text_input("NT/TTL/OWL/RDF è·¯å¾„", value=st.session_state.get("loaded_file", ""))
            if st.button("åŠ è½½æ•°æ®", type="primary", use_container_width=True):
                try:
                    g = load_graph_any(data_file)
                    st.session_state["graph"] = g
                    st.session_state["loaded_file"] = data_file
                    st.success(f"å·²åŠ è½½ï¼š{data_file}ï¼ˆtriples={len(g)}ï¼‰")
                except Exception as e:
                    st.error(f"åŠ è½½å¤±è´¥ï¼š{e}")
    else:
        # å…¨å±€æ•°æ®æºå·²è¿æ¥æ—¶ç»™å‡ºæ˜ç¡®æç¤º
        with st.sidebar:
            st.header("ğŸ“ æ•°æ®")
            st.success(f"å·²è¿æ¥å…¨å±€æ•°æ®æºï¼š{st.session_state.get('loaded_file','')}")
            if reloaded:
                st.info("å·²æ ¹æ®å…¨å±€æ•°æ®æºè‡ªåŠ¨åŠ è½½ã€‚")

    g = st.session_state.get("graph")
    st.subheader("ğŸ‘¤ äººç‰©æ•°æ®å±æ€§æ£€ç´¢")

    if not g:
        st.info("ğŸ‘ˆ å…ˆåœ¨ä¾§æ åŠ è½½æœ¬ä½“æ•°æ®æ–‡ä»¶ï¼ˆ.nt/.ttl/.owl/.rdfï¼‰ï¼Œæˆ–åœ¨ä¸»å…¥å£åº”ç”¨å…¨å±€æ•°æ®æºåè‡ªåŠ¨å¤ç”¨ã€‚")
        return

    # é¡¶éƒ¨æœç´¢ï¼ˆ8/4ï¼‰
    col_q1, col_q2 = st.columns([8,4])
    with col_q1:
        q = st.text_input("è¾“å…¥äººåå…³é”®å­—ï¼ˆç¹ç®€å‡å¯ï¼‰", value=st.session_state.get("__pp_attrs_last_query__", ""))
    with col_q2:
        if st.button("ğŸ” æœç´¢", type="primary", use_container_width=True):
            st.session_state["__pp_attrs_last_query__"] = q

    # å‘½ä¸­åˆ—è¡¨
    hits: List[Tuple[str,str,str]] = []
    if st.session_state.get("__pp_attrs_last_query__", "").strip():
        hits = _search_persons(g, st.session_state["__pp_attrs_last_query__"])

    if not hits:
        st.info("è¾“å…¥äººåå¹¶ç‚¹å‡»â€œæœç´¢â€ã€‚")
        return

    st.success(f"å‘½ä¸­ {len(hits)} äººï¼ˆå±•ç¤ºå‰ {len(hits)}ï¼‰")
    st.divider()

    # ä¸»è§†å›¾ 8/4
    left, right = st.columns([8,4], gap="large")

    with left:
        for idx, (person_iri, _display_name, _reason) in enumerate(hits, 1):
            _render_person_block(g, person_iri)
            st.divider()

    with right:
        st.markdown("### æº¯æº")
        sel = st.session_state.get("__pp_attrs_prov__")
        if not sel:
            st.info("ç‚¹å‡»å·¦ä¾§ä»»ä¸€å±æ€§ Chip æŸ¥çœ‹æº¯æºã€‚åªå±•ç¤ºåŒ…å«è¯¥äººç‰©â€˜å§“å/å­—å·â€™çš„æ‘˜å½•ï¼Œå¹¶å¯¹æ‰€ç‚¹å€¼åšç¹ç®€ä½“è”åŠ¨é«˜äº®ã€‚")
        else:
            node_iri, prop_name, prop_value, aliases = sel
            node = URIRef(node_iri)
            st.markdown(f"**å®šä½**ï¼šäººç‰©èŠ‚ç‚¹  |  **æ–­è¨€**ï¼š{prop_name} = {prop_value}")

            groups = provenance_groups_for(node, g, aliases, ALLOWED_FOR_PROV)
            filtered = [G for G in groups if (prop_name, prop_value) in G["items"]]

            if not filtered:
                st.warning("æœªæ‰¾åˆ°ä¸æ­¤å€¼ç›´æ¥åŒ¹é…ä¸”å«äººåçš„æº¯æºã€‚ï¼ˆå¯èƒ½è¯¥å€¼æš‚æ— æº¯æºæˆ–æº¯æºæ–‡æœ¬æœªå«äººå/å­—å·ï¼‰")
            else:
                for i, G in enumerate(filtered, 1):
                    with st.expander(f"#{i} ä¹¦ç›®ï¼š{G['src']}", expanded=(i==1)):
                        st.caption("è¯æ˜ï¼š " + "ï¼› ".join([f"{p} = {v}" for p,v in sorted(G["items"])]))
                        if G["conf"]:
                            st.write(f"**å¯ä¿¡åº¦ï¼š** {G['conf']}")
                        st.write("**æ‘˜å½•ï¼ˆè‡ªåŠ¨é«˜äº®ï¼Œå«ç¹ç®€ä½“ï¼‰**ï¼š", unsafe_allow_html=True)
                        st.markdown(highlight_value(G["body"], prop_value), unsafe_allow_html=True)
