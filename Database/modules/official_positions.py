# -*- coding: utf-8 -*-
"""
å®˜èŒå±¥å†å±•ç¤ºï¼ˆPerson Ã— OfficialPositionï¼ŒæŒ‰â€œèŒç³»â€æŠ˜å ï¼›å¿½ç•¥äº‹ä»¶ï¼‰
- ä¾›ä¸»å…¥å£ app.py è°ƒç”¨ï¼šofficial_positions.run(st)
- ä¼˜å…ˆå¤ç”¨ä¸»å…¥å£æ³¨å…¥çš„å…¨å±€æ•°æ®æºï¼š
    st.session_state['kd_data_path']  -> è‡ªåŠ¨åŠ è½½ Graph åˆ° st.session_state['graph']
  è‹¥æœªè®¾ç½®å…¨å±€æ•°æ®æºï¼Œåˆ™åœ¨æœ¬æ¨¡å—ä¾§æ æä¾›â€œåŠ è½½æ•°æ®â€å…¥å£ã€‚
- èŒç³»é¢æ¿å†…ï¼šç›´æ¥åˆ—å‡ºå®˜èŒå®ä¾‹â€œå®˜èŒåç§°â€ï¼ˆæ›´é†’ç›®ï¼‰ï¼Œæä¾›æº¯æº Chip
- è¯¦ç»†ä¿¡æ¯ï¼šé»˜è®¤éšè—â€œå¯¹é½ç _*â€å­—æ®µï¼ˆå¯æŒ‰å®ä¾‹å¼€å…³æ˜¾ç¤ºï¼‰
- å¸ƒå±€ï¼š8/4ï¼›å»ä¸¤ä¾§ç•™ç™½ï¼›æ‰€æœ‰ session_state å¸¦æ¨¡å—å‰ç¼€ä»¥é˜²å†²çª
"""

import unicodedata
from pathlib import Path
from typing import List, Dict, Set, Tuple, Optional, Union

import streamlit as st
from rdflib import Graph, URIRef, Literal
from rdflib.namespace import RDFS, SKOS, FOAF

# ====== åŸºæœ¬é…ç½® ======
NS = "http://mingkg.org/ontology/imperial_exam.owl#"

# â€”â€” å¯¹è±¡å±æ€§ï¼ˆURIï¼‰â€”â€”
APPOINTED_IN = NS + "appointedIn"    # Person -> AppointmentEvent
HAS_POSITION = NS + "hasPosition"    # AppointmentEvent -> OfficialPosition
ABOUT        = NS + "about"          # PropAssertion -> owl:Thing
DERIVED_FROM = NS + "derivedFrom"    # PropAssertion -> TextProvenance

# â€”â€” æ•°æ®å±æ€§ï¼ˆPropAssertion & TextProvenanceï¼‰â€”â€”
PA_PROP  = NS + "prop"
PA_VAL   = NS + "value"
PA_VALN  = NS + "value_norm"
TP_CONF  = NS + "record_confidence"
TP_SRC   = NS + "Text_source"
TP_BODY  = NS + "Text_body"

# â€”â€” æ–‡æœ¬åå€™é€‰ â€”â€” #
NAME_PROPS = [
    NS + "å§“å", NS + "å­—",
    str(RDFS.label), str(SKOS.prefLabel), str(FOAF.name),
]
POSITION_NAME_PROPS = [
    str(RDFS.label), str(SKOS.prefLabel),
    NS + "å®˜èŒåç§°", NS + "åŸå§‹ç§°è°“",
]

# â€”â€” å®˜èŒç›®æ ‡â€œæœ¬åœ°åâ€æ¸…å•ï¼ˆä¸çœ‹å‘½åç©ºé—´ï¼Œåªçœ‹å°¾å·´ï¼‰â€”â€” #
OP_LOCAL_KEYS_ORDERED = [
    "æ ¸å¿ƒèŒç§°", "å±‚çº§", "æœºæ„", "èŒç³»",
    "ä¿®é¥°_æ–¹ä½", "ä¿®é¥°_å‰¯", "åœ°å",
    "å¯¹é½ç _core", "å¯¹é½ç _inst", "å¯¹é½ç _tier",
    "å¯¹é½ç _loc_core", "å¯¹é½ç _loc_inst", "å¯¹é½ç _loc_full",
    "åŸå§‹ç§°è°“", "å®˜èŒåç§°",
]
ALIGN_KEYS_PREFIX = ("å¯¹é½ç _",)  # å¯¹é½ç å­—æ®µå‰ç¼€é›†åˆ
WANTED_PA_FOR_PROV: Set[str] = set(OP_LOCAL_KEYS_ORDERED)

# â€”â€” å±‚çº§æ’åºï¼ˆæ‰§è¡Œ â†’ åˆ†ç®¡ â†’ å†³ç­– â†’ å…¶ä»–ï¼‰â€”â€” #
TIER_ORDER = {"æ‰§è¡Œ": 0, "åˆ†ç®¡": 1, "å†³ç­–": 2}
def tier_rank(t: str) -> int:
    return TIER_ORDER.get(t or "", 3)

# ====== æ ·å¼ï¼ˆä»…åœ¨ run å†…æ³¨å…¥ï¼›ä¸è°ƒç”¨ set_page_configï¼‰ ======
CSS = """
<style>
.block-container { max-width:96vw; padding-left:8px; padding-right:8px; }
.card { border:1px solid #ececec; border-radius:16px; padding:14px 16px; margin:10px 0; background:#fff; box-shadow:0 1px 3px rgba(0,0,0,.04); }
.badge {display:inline-block; padding:2px 10px; border-radius:999px; font-size:12px; background:#f1f5f9; color:#0f172a; margin-right:6px; border:1px solid #e2e8f0;}
.hint { color:#94a3b8; font-size:12px; }
.small { color:#64748b; font-size:12px; }
.grid6 { display:grid; grid-template-columns: repeat(6, minmax(0, 1fr)); grid-gap:8px; margin-top:6px; }
.chip { width:100%; border:1px solid #c7d2fe; background:#eef2ff; color:#1e293b; border-radius:999px; padding:8px 10px; font-size:13px; text-align:center; cursor:pointer; }
.chip:hover { background:#e0e7ff; }
.mark { background:#fde68a; padding:0 3px; border-radius:4px; }

/* â€”â€” å®˜èŒå®ä¾‹è¡Œï¼ˆæ›´æ¸…æ™°ï¼‰ â€”â€” */
.op-item { display:flex; align-items:center; justify-content:space-between;
  padding:10px 12px; border:1px solid #e5e7eb; border-radius:12px; margin:8px 0;
  background:#fafafa; }
.op-item:hover { background:#f5f7fa; }
.op-name { font-weight:700; font-size:15px; color:#111827; }
.op-meta { color:#6b7280; font-size:12px; margin-left:10px; }
</style>
"""

# ====== å·¥å…·å‡½æ•° ======
_ZW = {u"\u200b", u"\u200c", u"\u200d", u"\ufeff"}
def norm(s: str) -> str:
    if s is None: return ""
    s = unicodedata.normalize("NFKC", s)
    s = "".join(ch for ch in s if (not ch.isspace()) and (ch not in _ZW))
    return s

def iri_tail(u: URIRef) -> str:
    s = str(u)
    if "#" in s: s = s.rsplit("#", 1)[-1]
    elif "/" in s: s = s.rsplit("/", 1)[-1]
    return s

@st.cache_data(show_spinner=False)
def load_graph_any(path: str) -> Graph:
    p = Path(path)
    data = p.read_bytes()
    g = Graph()
    # æ›´é²æ£’çš„åˆ¤å®šé¡ºåº
    try:
        g.parse(data=data, format="nt")
    except Exception:
        try:
            g = Graph(); g.parse(data=data, format="turtle")
        except Exception:
            g = Graph(); g.parse(data=data)  # äº¤ç»™ rdflib è‡ªåŠ¨åˆ¤å®š
    return g

def objects_literals(g: Graph, s: URIRef, prop_uri: str) -> List[Literal]:
    return [o for o in g.objects(s, URIRef(prop_uri)) if isinstance(o, Literal)]

def txt_list(g: Graph, s: URIRef, prop_uri: str) -> List[str]:
    vals, seen = [], set()
    for lit in objects_literals(g, s, URIRef(prop_uri)):
        v = str(lit).strip()
        if v and v not in seen:
            seen.add(v); vals.append(v)
    return vals

def persons_with_appts(g: Graph) -> Set[URIRef]:
    return set(s for s,_,_ in g.triples((None, URIRef(APPOINTED_IN), None)) if isinstance(s, URIRef))

def appts_of(g: Graph, p: URIRef) -> List[URIRef]:
    return [o for _,_,o in g.triples((p, URIRef(APPOINTED_IN), None)) if isinstance(o, URIRef)]

def positions_of_appt(g: Graph, e: URIRef) -> List[URIRef]:
    return [o for _,_,o in g.triples((e, URIRef(HAS_POSITION), None)) if isinstance(o, URIRef)]

def pred_tail(p) -> str:
    s = str(p)
    if "#" in s: return s.rsplit("#", 1)[-1]
    if "/" in s: return s.rsplit("/", 1)[-1]
    return s

def values_by_localname(g: Graph, subj: URIRef, local_name: str) -> List[str]:
    out, seen = [], set()
    for _, p, o in g.triples((subj, None, None)):
        if pred_tail(p) == local_name and isinstance(o, Literal):
            v = str(o).strip()
            if v and v not in seen:
                seen.add(v); out.append(v)
    return out

def pick_label(g: Graph, node: URIRef, props: List[str]) -> str:
    for u in props:
        for lit in objects_literals(g, node, URIRef(u)):
            s = str(lit).strip()
            if s: return s
    return ""

def aggregate_names(g: Graph, p: URIRef) -> List[str]:
    vals, seen = [], set()
    for u in NAME_PROPS:
        for lit in objects_literals(g, p, URIRef(u)):
            s = str(lit).strip()
            if s and s not in seen:
                seen.add(s); vals.append(s)
    return vals

def prop_assertions_about(g: Graph, node: URIRef) -> List[URIRef]:
    return [pa for pa in g.subjects(URIRef(ABOUT), node)]

def pa_core_tuple(g: Graph, pa: URIRef) -> Tuple[str, str]:
    prop = next(iter(txt_list(g, pa, PA_PROP)), "")
    valn = next(iter(txt_list(g, pa, PA_VALN)), "")
    if valn:
        return prop, valn
    val = next(iter(txt_list(g, pa, PA_VAL)), "")
    return prop, val

def pa_to_provenances(g: Graph, pa: URIRef) -> List[URIRef]:
    return [tp for tp in g.objects(pa, URIRef(DERIVED_FROM)) if isinstance(tp, URIRef)]

# â€”â€” æº¯æºï¼ˆå»é‡ + é«˜äº®å€¼ï¼Œä»…å–å«äººåçš„æ–‡æœ¬ï¼‰ â€”â€” #
TS_MAP = {"è˜‡":"è‹","åŠ‰":"åˆ˜","å¼µ":"å¼ ","è¶™":"èµµ","éŒ¢":"é’±","å­«":"å­™","åœ‹":"å›½","æœƒ":"ä¼š","è©¦":"è¯•","é„‰":"ä¹¡",
          "é€²":"è¿›","èˆ‰":"ä¸¾","éš":"é˜¶","ç´š":"çº§","æ­·":"å†","é„­":"éƒ‘","é»ƒ":"é»„","è¬":"ä¸‡","é™³":"é™ˆ","æ¥Š":"æ¨",
          "é¦¬":"é©¬","è¨±":"è®¸","é„§":"é‚“","å³":"å´","è‘‰":"å¶","ç¾…":"ç½—","é½Š":"é½","ç¥¿":"ç¦„","ç¥¯":"ç¥¯","ç¦":"ç¥¯"}
def t2s(s: str) -> str: return "".join(TS_MAP.get(ch, ch) for ch in s)
def s2t(s: str):
    inv = getattr(s2t, "_inv", None)
    if inv is None:
        inv = {v:k for k,v in TS_MAP.items()}
        s2t._inv = inv
    return "".join(inv.get(ch, ch) for ch in s)

def fuzzy_contains_name(text: str, names: List[str]) -> bool:
    if not text or not names: return False
    t_raw = norm(text); t_s = t2s(t_raw); t_t = s2t(t_raw)
    for name in names:
        n_raw = norm(name); n_s = t2s(n_raw); n_t = s2t(n_raw)
        if (n_raw and n_raw in t_raw) or (n_s and n_s in t_s) or (n_t and n_t in t_t):
            return True
    return False

def provenance_groups_for(node: URIRef, g: Graph, person_aliases: List[str]) -> List[Dict]:
    groups: Dict[Tuple[str,str], Dict] = {}
    def _n(s): return norm(s or "")
    for pa in prop_assertions_about(g, node):
        prop, val = pa_core_tuple(g, pa)
        # è¿™é‡Œçš„ prop æ˜¯ PropAssertion.prop çš„æ–‡æœ¬å€¼ï¼ˆé€šå¸¸æ˜¯â€œæœ¬åœ°åâ€æˆ–åŸå­—æ®µåï¼‰
        if not prop or not val or (prop not in WANTED_PA_FOR_PROV and pred_tail(prop) not in WANTED_PA_FOR_PROV):
            continue
        for tp in pa_to_provenances(g, pa):
            srcs  = txt_list(g, tp, TP_SRC)
            confs = txt_list(g, tp, TP_CONF)
            bodys = txt_list(g, tp, TP_BODY)
            src = srcs[0] if srcs else ""
            body = bodys[0] if bodys else ""
            if not body: continue
            if not fuzzy_contains_name(body, person_aliases): continue
            key = (_n(src), _n(body))
            G = groups.setdefault(key, {"src": src or "ï¼ˆæœªçŸ¥ä¹¦ç›®ï¼‰", "body": body, "conf": "", "items": set()})
            if confs:
                try:
                    cur = float(G["conf"]) if G["conf"] else -1e9
                    valf = float(confs[0])
                    if valf > cur:
                        G["conf"] = confs[0]
                except Exception:
                    pass
            G["items"].add((prop, val))
    ordered = sorted(groups.values(), key=lambda d: (0 if d["src"] else 1, d["src"], d["body"]))
    return ordered

def highlight_value(text: str, value: str) -> str:
    if not text or not value: return text
    t = text
    cands = list(dict.fromkeys([value, t2s(value), s2t(value)]))
    for v in cands:
        vv = v.strip()
        if vv:
            t = t.replace(vv, f"<span class='mark'>{vv}</span>")
    return t

# ====== å†…éƒ¨çŠ¶æ€é”®ï¼ˆåŠ å‰ç¼€ï¼Œé¿å…ä¸å…¶ä»–æ¨¡å—å†²çªï¼‰ ======
KEY_LAST_QUERY = "__op_last_query__"
KEY_HITS       = "__op_hits__"
KEY_PROV       = "__op_prov__"  # (node_type, node_iri, prop_name, prop_value, aliases)

# ====== å…¨å±€æ•°æ®æºæ¥å…¥ï¼ˆæ–¹æ¡ˆ Aï¼‰ ======
def _ensure_graph_from_global() -> Tuple[Optional[Graph], bool]:
    """
    è‹¥ä¸»å…¥å£å·²è®¾ç½® kd_data_pathï¼Œåˆ™è‡ªåŠ¨åŠ è½½ Graph å¹¶å†™å…¥ï¼š
      - st.session_state['graph']
      - st.session_state['loaded_file']
    è¿”å› (Graph or None, æ˜¯å¦æœ¬æ¬¡é‡æ–°åŠ è½½)
    """
    kd_path = (st.session_state.get("kd_data_path") or "").strip()
    if not kd_path:
        return None, False
    cur_loaded = st.session_state.get("loaded_file", "")
    g = st.session_state.get("graph")
    if g is not None and cur_loaded == kd_path:
        return g, False
    try:
        g = load_graph_any(kd_path)
        st.session_state.graph = g
        st.session_state.loaded_file = kd_path
        return g, True
    except Exception as e:
        st.error(f"å…¨å±€æ•°æ®æºåŠ è½½å¤±è´¥ï¼š{e}")
        return None, False

# ====== è¾…åŠ© ======
def values_safe_first(lst: List[str], default: str="â€”") -> str:
    return (lst[0] if lst else default) or default

def search_persons(g: Graph, query: str) -> List[Tuple[str, str, str]]:
    persons = persons_with_appts(g)
    qn = norm(query.strip())
    hits = []
    for p in persons:
        names = aggregate_names(g, p)
        if not names: continue
        reason = ""
        for v in names:
            if qn and norm(v) == qn:
                reason = f"[ç­‰å€¼å‘½ä¸­] {v}"; break
        if not reason:
            for v in names:
                if qn and qn in norm(v):
                    reason = f"[åŒ…å«å‘½ä¸­] {v}"; break
        if reason:
            hits.append((str(p), names[0], reason))
    hits.sort(key=lambda t: (t[1]))
    return hits[:30]

def bucket_positions_by_family(g: Graph, ops: List[URIRef]) -> Dict[str, List[URIRef]]:
    buckets: Dict[str, List[URIRef]] = {}
    for op in ops:
        families = values_by_localname(g, op, "èŒç³»")
        if not families:
            buckets.setdefault("(æœªè¯†åˆ«èŒç³»)", []).append(op)
        else:
            for fam in sorted(set(families)):
                buckets.setdefault(fam, []).append(op)
    return buckets

def sort_positions_for_bucket(g: Graph, pos_list: List[URIRef]) -> List[URIRef]:
    def key(op):
        tier  = values_safe_first(values_by_localname(g, op, "å±‚çº§"), "")
        inst  = values_safe_first(values_by_localname(g, op, "æœºæ„"), "")
        core  = values_safe_first(values_by_localname(g, op, "æ ¸å¿ƒèŒç§°"), "")
        label = pick_label(g, op, POSITION_NAME_PROPS) or iri_tail(op)
        return (tier_rank(tier), inst, core, label, str(op))
    return sorted(pos_list, key=key)

def render_position_name(g: Graph, op: URIRef) -> str:
    name = (values_by_localname(g, op, "å®˜èŒåç§°")
            or values_by_localname(g, op, "åŸå§‹ç§°è°“")
            or [pick_label(g, op, POSITION_NAME_PROPS)]
            or ["â€”"])[0] or "â€”"
    return name

# ====== å¯¹å¤–å…¥å£ ======
def run(st):
    # æ³¨å…¥æ ·å¼ï¼ˆä¸ set_page_configï¼Œé¿å…ä¸ä¸»å…¥å£å†²çªï¼‰
    st.markdown(CSS, unsafe_allow_html=True)

    # ä¼˜å…ˆå¤ç”¨ä¸»å…¥å£çš„å…¨å±€æ•°æ®æº
    g, reloaded = _ensure_graph_from_global()

    # è‹¥ä¸»å…¥å£æœªæ³¨å…¥å›¾è°±ï¼Œè¿™é‡Œæä¾›åŠ è½½å…¥å£ï¼›è‹¥å·²å¤ç”¨å…¨å±€ï¼Œåˆ™éšè—æ–‡ä»¶è¾“å…¥
    if g is None and (st.session_state.get("graph") is None):
        with st.sidebar:
            st.header("ğŸ“ æ•°æ®")
            data_file = st.text_input("NT/TTL/OWL è·¯å¾„", value=st.session_state.get("loaded_file", ""))
            if st.button("åŠ è½½æ•°æ®", type="primary", use_container_width=True):
                try:
                    g = load_graph_any(data_file)
                    st.session_state.graph = g
                    st.session_state.loaded_file = data_file
                    st.success(f"å·²åŠ è½½ï¼š{data_file}ï¼ˆtriples={len(g)}ï¼‰")
                except Exception as e:
                    st.error(f"åŠ è½½å¤±è´¥ï¼š{e}")
    else:
        with st.sidebar:
            st.header("ğŸ“ æ•°æ®")
            st.success(f"å·²è¿æ¥å…¨å±€æ•°æ®æºï¼š{st.session_state.get('loaded_file','')}")
            if reloaded:
                st.info("å·²æ ¹æ®å…¨å±€æ•°æ®æºè‡ªåŠ¨åŠ è½½ã€‚")

    g: Optional[Graph] = st.session_state.get("graph")
    st.subheader("ç§‘ä¸¾äººç‰©å®˜èŒä¿¡æ¯æ£€ç´¢")

    if not g:
        st.info("ğŸ‘ˆ å…ˆåœ¨ä¾§æ åŠ è½½æœ¬ä½“æ•°æ®æ–‡ä»¶ï¼ˆ.nt/.ttl/.owlï¼‰ï¼Œæˆ–åœ¨ä¸»å…¥å£è®¾ç½®å…¨å±€æ•°æ®æºåè‡ªåŠ¨å¤ç”¨ã€‚")
        return

    # æ£€ç´¢æ ï¼ˆ8/4ï¼‰
    col_q1, col_q2 = st.columns([8,4])
    with col_q1:
        q = st.text_input("è¾“å…¥äººåå…³é”®å­—ï¼ˆç¹ç®€å‡å¯ï¼šè˜‡åœ‹ç““ / è‹å›½ç““ï¼‰", value=st.session_state.get(KEY_LAST_QUERY, ""))
    with col_q2:
        if st.button("ğŸ” æœç´¢", type="primary", use_container_width=True):
            st.session_state[KEY_LAST_QUERY] = q

    # æœç´¢
    hits: List[Tuple[str,str,str]] = []
    if st.session_state.get(KEY_LAST_QUERY, "").strip():
        hits = search_persons(g, st.session_state[KEY_LAST_QUERY])

    if not hits:
        st.info("è¾“å…¥äººåå¹¶ç‚¹å‡»â€œæœç´¢â€ã€‚")
        return

    st.success(f"å‘½ä¸­ {len(hits)} äººï¼ˆå±•ç¤ºå‰ {len(hits)} ï¼‰")
    st.divider()

    # ä¸»è§†å›¾ï¼šå·¦ï¼ˆ8ï¼‰/å³ï¼ˆ4ï¼‰
    left, right = st.columns([8,4], gap="large")

    # æº¯æºå›è°ƒ
    def set_prov(node_type: str, node_iri: str, prop_name: str, prop_value: str, aliases: List[str]):
        st.session_state[KEY_PROV] = (node_type, node_iri, prop_name, prop_value, aliases)

    with left:
        for idx, (person_iri, display_name, reason) in enumerate(hits, 1):
            person = URIRef(person_iri)
            aliases = aggregate_names(g, person)
            st.markdown(f"### {idx}. {display_name}  <span class='hint'>{reason}</span>", unsafe_allow_html=True)

            # æ”¶é›†å®˜èŒå®ä¾‹
            ops, seen = [], set()
            for e in appts_of(g, person):
                for op in positions_of_appt(g, e):
                    if op not in seen:
                        seen.add(op); ops.append(op)
            st.markdown(f"<span class='small'>å®˜èŒå®ä¾‹æ•°ï¼š{len(ops)}</span>", unsafe_allow_html=True)

            buckets = bucket_positions_by_family(g, ops)
            if not buckets:
                st.info("ï¼ˆæ— å®˜èŒå®ä¾‹ï¼‰")
                st.divider()
                continue

            # â€”â€” èŒç³»æŠ˜å ï¼šå±•å¼€ååˆ—â€œå®˜èŒåç§°â€å¡ç‰‡è¡Œï¼ˆä¸æ˜¾ç¤ºå±‚çº§/æ ¸å¿ƒèŒç§°ï¼‰ â€”â€” #
            for fam in sorted(buckets.keys(), key=lambda s: (s=="(æœªè¯†åˆ«èŒç³»)", s)):
                pos_list_sorted = sort_positions_for_bucket(g, buckets[fam])
                with st.expander(f"ğŸ·ï¸ èŒç³»ï¼š{fam}ï¼ˆ{len(pos_list_sorted)}ï¼‰", expanded=False):
                    for k, op in enumerate(pos_list_sorted, 1):
                        name = render_position_name(g, op)
                        iri_short = iri_tail(op)

                        # å·¦å³ä¸¤åˆ—ï¼šå®ä¾‹è¡Œ + è¯¥å­—æ®µæº¯æºæŒ‰é’®
                        colA, colB = st.columns([7,5])
                        with colA:
                            st.markdown(
                                f"<div class='op-item'>"
                                f"  <div class='op-name'>{k}. {name}</div>"
                                f"  <div class='op-meta'>IDï¼š{iri_short}</div>"
                                f"</div>",
                                unsafe_allow_html=True
                            )
                        with colB:
                            prov_key = f"prov_name_chip_{hash((str(op), name))}"
                            st.button("å®˜èŒåç§°Â·æº¯æº", key=prov_key, on_click=set_prov,
                                      args=("position", str(op), "å®˜èŒåç§°", name, aliases),
                                      use_container_width=True)

                        # æ˜ç»†ï¼ˆé»˜è®¤éšè—â€œå¯¹é½ç _*â€ï¼‰
                        with st.expander("è¯¦ç»†ä¿¡æ¯", expanded=False):
                            key_show_align = f"show_align_{hash(str(op))}"
                            show_align = st.checkbox("æ˜¾ç¤ºå¯¹é½ç å­—æ®µ", value=False, key=key_show_align)

                            chips: List[Tuple[str,str]] = []
                            for local_name in OP_LOCAL_KEYS_ORDERED:
                                if (not show_align) and any(local_name.startswith(prefix) for prefix in ALIGN_KEYS_PREFIX):
                                    continue
                                for v in values_by_localname(g, op, local_name):
                                    chips.append((local_name, v))

                            if chips:
                                st.markdown("<div class='grid6'>", unsafe_allow_html=True)
                                for j, (pk, pv) in enumerate(chips):
                                    key = f"pos_chip_{hash((str(op), pk, pv))}_{j}"
                                    st.button(f"{pk}ï¼š{pv}", key=key, on_click=set_prov,
                                              args=("position", str(op), pk, pv, aliases),
                                              use_container_width=True)
                                st.markdown("</div>", unsafe_allow_html=True)
                            else:
                                st.markdown("<div class='hint'>ï¼ˆæ— å¯å±•ç¤ºçš„å®˜èŒå±æ€§ï¼‰</div>", unsafe_allow_html=True)

            st.divider()

    with right:
        st.markdown("### æº¯æº")
        sel = st.session_state.get(KEY_PROV)
        if not sel:
            st.info("ç‚¹å‡»å·¦ä¾§ä»»ä¸€å®˜èŒå±æ€§ Chip æˆ–ã€å®˜èŒåç§°Â·æº¯æºã€æŸ¥çœ‹æº¯æºã€‚åªå±•ç¤ºåŒ…å«è¯¥äººç‰©â€˜å§“å/å­—å·â€™çš„æ–‡æœ¬ï¼Œâ€˜ä¹¦ç›®+æ‘˜å½•â€™å»é‡ï¼Œå¹¶è‡ªåŠ¨é«˜äº®æ‰€ç‚¹çš„å…·ä½“å€¼ã€‚")
        else:
            node_type, node_iri, prop_name, prop_value, aliases = sel
            node = URIRef(node_iri)
            st.markdown(f"**å®šä½**ï¼šå®˜èŒ  |  **æ–­è¨€**ï¼š{prop_name} = {prop_value}")

            groups = provenance_groups_for(node, g, aliases)
            filtered = [G for G in groups if (prop_name, prop_value) in G["items"]]

            if not filtered:
                st.warning("æœªæ‰¾åˆ°ä¸æ­¤å€¼ç›´æ¥åŒ¹é…ä¸”å«äººåçš„æº¯æºã€‚ï¼ˆå¯èƒ½è¯¥å€¼æš‚æ— æº¯æºæˆ–æº¯æºæ–‡æœ¬æœªå«äººå/å­—å·ï¼‰")
            else:
                for i, G in enumerate(filtered, 1):
                    with st.expander(f"#{i} ä¹¦ç›®ï¼š{G['src']}", expanded=(i==1)):
                        st.caption("è¯æ˜ï¼š " + "ï¼› ".join([f"{p} = {v}" for p,v in sorted(G['items'])]))
                        if G["conf"]:
                            st.write(f"**å¯ä¿¡åº¦ï¼š** {G['conf']}")
                        st.write("**æ‘˜å½•ï¼ˆè‡ªåŠ¨é«˜äº®ï¼‰**ï¼š", unsafe_allow_html=True)
                        st.markdown(highlight_value(G["body"], prop_value), unsafe_allow_html=True)
